#!/bin/bash -l

#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=6
#SBATCH --mem=16384
#SBATCH --partition=gpu
#SBATCH --qos=gpu
#SBATCH --gres=gpu:1
#SBATCH --time=02:35:00
#SBATCH --output=/home/michels/results/taylor/s%x.out

module purge
module load gcc/8.4.0-cuda python/3.7.7
source /home/michels/venvs/taylor/bin/activate

shopt -s extglob

echo STARTING AT `date`
pwd

xpdir="/home/michels/results/taylor/${SLURM_JOB_NAME}"

mkdir -p ${xpdir}
mkdir -p ${xpdir}/logs

# Dataset
dataset='jaad'
jaadsubset='default'
trainsplit='train'
evalsplit='val'

# Training
lr=0.0005
epochs=1

# Model
mtlgradmerge='power'

attributes='detection will_cross'
duplicates=35
taskweight=7.0
lambdas="${taskweight} ${taskweight} ${taskweight} ${taskweight} 1.0"

sthreshold=0.2
minclustersize=10
epsilon=5.0
clusterthreshold=0.5

cd /home/michels/detection-attributes-fields/


echo "Start training..."
mkdir -p ${xpdir}/checkpoints

srun time python3 -m openpifpaf.train \
  --output ${xpdir}/checkpoints/model.pt \
  --dataset ${dataset} \
  --jaad-root-dir /work/vita/datasets/JAAD/ \
  --jaad-subset ${jaadsubset} \
  --jaad-training-set ${trainsplit} \
  --jaad-validation-set ${evalsplit} \
  --log-interval 10 \
  --val-interval 1 \
  --val-batches 1 \
  --epochs ${epochs} \
  --batch-size 4 \
  --lr ${lr} \
  --lr-warm-up-start-epoch -1 \
  --weight-decay 5e-4 \
  --momentum 0.95 \
  --basenet fn-resnet50 \
  --pifpaf-pretraining \
  --detection-bias-prior 0.01 \
  --jaad-head-upsample 2 \
  --jaad-pedestrian-attributes ${attributes} \
  --fork-normalization-operation ${mtlgradmerge} \
  --fork-normalization-duplicates ${duplicates} \
  --lambdas ${lambdas} \
  --attribute-regression-loss l1 \
  --attribute-focal-gamma 2 \
  --auto-tune-mtl \
  2>&1 | tee ${xpdir}/logs/train_log.txt
echo "Training done!"

mkdir -p ${xpdir}/predictions


cd -

echo FINISHED at `date`

deactivate